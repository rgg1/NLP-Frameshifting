{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File for exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_speech_data(congress_number):\n",
    "    \"\"\"\n",
    "    Load speech data for a given congress number with enhanced error handling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the speech texts\n",
    "        speeches_file = f'../small_speech_data/speeches_{congress_number}_trimmed.txt'\n",
    "        speech_df = pd.read_csv(\n",
    "            speeches_file, \n",
    "            delimiter='|', \n",
    "            names=['speech_id', 'speech_text'], \n",
    "            dtype={'speech_id': str, 'speech_text': str},\n",
    "            skiprows=1\n",
    "        )\n",
    "        \n",
    "        # Load the corresponding description file\n",
    "        desc_file = f'../small_speech_data/descr_{congress_number}.txt'\n",
    "        \n",
    "        # Read the column names from the first line\n",
    "        with open(desc_file, 'r') as f:\n",
    "            header = f.readline().strip().split('|')\n",
    "        \n",
    "        # Read the description file\n",
    "        desc_df = pd.read_csv(\n",
    "            desc_file,\n",
    "            delimiter='|',\n",
    "            names=header,\n",
    "            dtype={\n",
    "                'speech_id': str,\n",
    "                'chamber': str,\n",
    "                'date': str,\n",
    "                'number_within_file': str,\n",
    "                'speaker': str,\n",
    "                'first_name': str,\n",
    "                'last_name': str,\n",
    "                'state': str,\n",
    "                'gender': str,\n",
    "                'line_start': str,\n",
    "                'line_end': str,\n",
    "                'file': str,\n",
    "                'char_count': str,\n",
    "                'word_count': str\n",
    "            },\n",
    "            skiprows=1\n",
    "        )\n",
    "        \n",
    "        # Convert numeric columns after loading\n",
    "        desc_df['char_count'] = pd.to_numeric(desc_df['char_count'], errors='coerce')\n",
    "        desc_df['word_count'] = pd.to_numeric(desc_df['word_count'], errors='coerce')\n",
    "        desc_df['number_within_file'] = pd.to_numeric(desc_df['number_within_file'], errors='coerce')\n",
    "        \n",
    "        print(f\"\\nCongress {congress_number} data summary:\")\n",
    "        print(f\"Number of speeches: {len(speech_df)}\")\n",
    "        print(f\"Number of descriptions: {len(desc_df)}\")\n",
    "        \n",
    "        # Verify data types before merge\n",
    "        print(\"\\nData types in speech_df:\")\n",
    "        print(speech_df.dtypes)\n",
    "        print(\"\\nData types in desc_df:\")\n",
    "        print(desc_df.dtypes)\n",
    "        \n",
    "        # Check for any null speech_ids\n",
    "        print(\"\\nChecking for null speech_ids:\")\n",
    "        print(f\"Null speech_ids in speech_df: {speech_df['speech_id'].isnull().sum()}\")\n",
    "        print(f\"Null speech_ids in desc_df: {desc_df['speech_id'].isnull().sum()}\")\n",
    "        \n",
    "        # Check for duplicate speech_ids\n",
    "        print(\"\\nChecking for duplicate speech_ids:\")\n",
    "        print(f\"Duplicate speech_ids in speech_df: {speech_df['speech_id'].duplicated().sum()}\")\n",
    "        print(f\"Duplicate speech_ids in desc_df: {desc_df['speech_id'].duplicated().sum()}\")\n",
    "        \n",
    "        # Merge the dataframes\n",
    "        merged_df = pd.merge(speech_df, desc_df, on='speech_id', how='inner')\n",
    "        print(f\"\\nNumber of speeches after merge: {len(merged_df)}\")\n",
    "        \n",
    "        try:\n",
    "            # Try to add party information\n",
    "            merged_df = add_party_information(merged_df, congress_number)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nWarning: Could not add party information: {e}\")\n",
    "            print(\"Proceeding without party information\")\n",
    "        \n",
    "        return merged_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing congress {congress_number}\")\n",
    "        print(f\"Full error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_party_information(df, congress_number):\n",
    "    \"\"\"\n",
    "    Add party information using SpeakerMap files with enhanced error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        speaker_map_file = f'../small_speech_data/{congress_number}_SpeakerMap.txt'\n",
    "        \n",
    "        print(f\"\\nAttempting to load SpeakerMap file: {speaker_map_file}\")\n",
    "        \n",
    "        # First check if file exists\n",
    "        if not os.path.exists(speaker_map_file):\n",
    "            print(f\"Warning: SpeakerMap file not found: {speaker_map_file}\")\n",
    "            return df\n",
    "        \n",
    "        # Read the header first\n",
    "        with open(speaker_map_file, 'r') as f:\n",
    "            header = f.readline().strip().split('|')\n",
    "            print(f\"SpeakerMap headers: {header}\")\n",
    "        \n",
    "        # Read the SpeakerMap file\n",
    "        speaker_df = pd.read_csv(\n",
    "            speaker_map_file,\n",
    "            delimiter='|',\n",
    "            names=header,\n",
    "            dtype=str,  # Read all columns as strings initially\n",
    "            skiprows=1\n",
    "        )\n",
    "        \n",
    "        print(f\"Loaded SpeakerMap data: {len(speaker_df)} rows\")\n",
    "        \n",
    "        if 'speech_id' not in speaker_df.columns:\n",
    "            print(\"Warning: No speech_id column in SpeakerMap file\")\n",
    "            return df\n",
    "            \n",
    "        if 'party' not in speaker_df.columns:\n",
    "            print(\"Warning: No party column in SpeakerMap file\")\n",
    "            return df\n",
    "        \n",
    "        # Merge party information\n",
    "        df = pd.merge(\n",
    "            df,\n",
    "            speaker_df[['speech_id', 'party']],\n",
    "            on='speech_id',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        print(\"\\nParty information summary:\")\n",
    "        print(df['party'].value_counts(dropna=False))\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in add_party_information: {str(e)}\")\n",
    "        print(\"Proceeding without party information\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_speech_lengths(df):\n",
    "    \"\"\"\n",
    "    Analyze the distribution of speech lengths.\n",
    "    \"\"\"\n",
    "    df['word_count'] = df['speech_text'].str.split().str.len()\n",
    "    \n",
    "    stats = {\n",
    "        'mean_length': df['word_count'].mean(),\n",
    "        'median_length': df['word_count'].median(),\n",
    "        'std_length': df['word_count'].std(),\n",
    "        'min_length': df['word_count'].min(),\n",
    "        'max_length': df['word_count'].max(),\n",
    "        'quartiles': df['word_count'].quantile([0.25, 0.5, 0.75]).to_dict()\n",
    "    }\n",
    "\n",
    "    # create a dict that for every range of 50 words, counts the number of speeches in that range\n",
    "    # so like, how many speeches have between 0 and 50 words, how many have between 51 and 100 words, etc.\n",
    "    word_count_ranges = defaultdict(int)\n",
    "    for word_count in df['word_count']:\n",
    "        word_count_ranges[word_count // 50] += 1\n",
    "    # print how many are between 0 and 50, 51 and 1000, 101 to 150, 151 to 200, 201 to 250, 251 to 300, 301 to 350, 251 to 400\n",
    "    print(\"Word count ranges:\")\n",
    "    for i in range(0, 400, 50):\n",
    "        print(f\"{i}-{i+50}: {word_count_ranges[i // 50]}\")\n",
    "    \n",
    "    # Plot length distribution with log scale\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(data=df['word_count'], bins=50)\n",
    "    plt.title('Distribution of Speech Lengths')\n",
    "    plt.xlabel('Number of Words')\n",
    "    plt.ylabel('Count')\n",
    "    plt.yscale('log')  # Using log scale for better visualization\n",
    "    plt.show()\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_topic_file(filename):\n",
    "    \"\"\"\n",
    "    Clean a topic file by fixing malformed lines and returning clean data\n",
    "    \"\"\"\n",
    "    clean_lines = []\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "            for i, line in enumerate(lines, 1):\n",
    "                line = line.strip()\n",
    "                if not line:  # Skip empty lines\n",
    "                    continue\n",
    "                    \n",
    "                # Split on pipe\n",
    "                parts = line.split('|')\n",
    "                \n",
    "                if len(parts) == 2:\n",
    "                    # Line is good, add it as is\n",
    "                    clean_lines.append(line)\n",
    "                elif len(parts) > 2:\n",
    "                    # Try to fix malformed line\n",
    "                    # Look for pattern: topic|phrase|topic|phrase\n",
    "                    if len(parts) == 4 and parts[0] and parts[2]:\n",
    "                        # Split into two lines\n",
    "                        clean_lines.append(f\"{parts[0]}|{parts[1]}\")\n",
    "                        clean_lines.append(f\"{parts[2]}|{parts[3]}\")\n",
    "                    else:\n",
    "                        print(f\"Warning: Skipping malformed line {i}: {line}\")\n",
    "                else:\n",
    "                    print(f\"Warning: Skipping invalid line {i}: {line}\")\n",
    "        \n",
    "        # Write cleaned data to temporary file\n",
    "        temp_filename = f\"cleaned_{os.path.basename(filename)}\"\n",
    "        with open(temp_filename, 'w', encoding='utf-8') as f:\n",
    "            for line in clean_lines:\n",
    "                f.write(line + '\\n')\n",
    "        \n",
    "        return temp_filename\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning file {filename}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_topic_files():\n",
    "    \"\"\"\n",
    "    Load and validate topic-related files\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean files first\n",
    "        files_to_clean = {\n",
    "            'topic_phrases': '../phrase_clusters/topic_phrases.txt',\n",
    "            'keywords': '../phrase_clusters/keywords.txt',\n",
    "            'false_matches': '../phrase_clusters/false_matches.txt'\n",
    "        }\n",
    "        \n",
    "        cleaned_files = {}\n",
    "        for key, filepath in files_to_clean.items():\n",
    "            cleaned_filepath = clean_topic_file(filepath)\n",
    "            if cleaned_filepath is None:\n",
    "                return None\n",
    "            cleaned_files[key] = cleaned_filepath\n",
    "        \n",
    "        # Load cleaned files\n",
    "        topic_phrases = pd.read_csv(\n",
    "            cleaned_files['topic_phrases'],\n",
    "            delimiter='|',\n",
    "            names=['topic', 'phrase'],\n",
    "            dtype={'topic': str, 'phrase': str}\n",
    "        )\n",
    "        \n",
    "        keywords = pd.read_csv(\n",
    "            cleaned_files['keywords'],\n",
    "            delimiter='|',\n",
    "            names=['topic', 'phrase'],\n",
    "            dtype={'topic': str, 'phrase': str}\n",
    "        )\n",
    "        \n",
    "        false_matches = pd.read_csv(\n",
    "            cleaned_files['false_matches'],\n",
    "            delimiter='|',\n",
    "            names=['topic', 'phrase'],\n",
    "            dtype={'topic': str, 'phrase': str}\n",
    "        )\n",
    "        \n",
    "        # Clean up temporary files\n",
    "        for filepath in cleaned_files.values():\n",
    "            try:\n",
    "                os.remove(filepath)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Topic thresholds from codebook\n",
    "        topic_thresholds = {\n",
    "            'alcohol': 50, 'budget': 125, 'business': 75,\n",
    "            'crime': 50, 'defense': 75, 'economy': 50,\n",
    "            'education': 50, 'elections': 50, 'environment': 50,\n",
    "            'federalism': 125, 'foreign': 125, 'government': 75,\n",
    "            'health': 50, 'immigration': 50, 'justice': 50,\n",
    "            'labor': 75, 'mail': 50, 'minorities': 50,\n",
    "            'money': 50, 'religion': 50, 'tax': 50, 'trade': 50\n",
    "        }\n",
    "        \n",
    "        # Validate data\n",
    "        topics = set(topic_thresholds.keys())\n",
    "        found_topics = set(topic_phrases['topic'].unique())\n",
    "        \n",
    "        print(\"\\nTopic Validation:\")\n",
    "        print(f\"Expected topics: {len(topics)}\")\n",
    "        print(f\"Found topics: {len(found_topics)}\")\n",
    "        print(f\"Missing topics: {topics - found_topics}\")\n",
    "        print(f\"Extra topics: {found_topics - topics}\")\n",
    "        \n",
    "        print(\"\\nData Summary:\")\n",
    "        print(f\"Topic phrases: {len(topic_phrases)}\")\n",
    "        print(f\"Keywords: {len(keywords)}\")\n",
    "        print(f\"False matches: {len(false_matches)}\")\n",
    "        \n",
    "        return {\n",
    "            'topic_phrases': topic_phrases,\n",
    "            'keywords': keywords,\n",
    "            'false_matches': false_matches,\n",
    "            'thresholds': topic_thresholds,\n",
    "            'unique_topics': sorted(topic_phrases['topic'].unique())\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading topic files: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_speech_topics(speech_text, topic_data):\n",
    "    \"\"\"\n",
    "    Analyze topics in a speech with occurrence-based thresholds.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase and clean text\n",
    "    text = speech_text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Initialize results\n",
    "    topics_found = defaultdict(lambda: {'count': 0, 'evidence': []})\n",
    "    debug_info = {\n",
    "        'keywords_checked': 0,\n",
    "        'keywords_found': 0,\n",
    "        'phrases_checked': 0,\n",
    "        'phrases_found': 0,\n",
    "        'false_matches': 0\n",
    "    }\n",
    "    \n",
    "    # Check keywords\n",
    "    for _, row in topic_data['keywords'].iterrows():\n",
    "        keyword = row['phrase'].lower()\n",
    "        topic = row['topic']\n",
    "        debug_info['keywords_checked'] += 1\n",
    "        \n",
    "        if f\" {keyword} \" in f\" {text} \":\n",
    "            # Check if it's a false match\n",
    "            is_false = any(\n",
    "                f\" {fm.lower()} \" in f\" {text} \"\n",
    "                for fm in topic_data['false_matches'][\n",
    "                    topic_data['false_matches']['topic'] == topic\n",
    "                ]['phrase']\n",
    "            )\n",
    "            \n",
    "            if is_false:\n",
    "                debug_info['false_matches'] += 1\n",
    "            else:\n",
    "                debug_info['keywords_found'] += 1\n",
    "                topics_found[topic]['count'] += 1\n",
    "                topics_found[topic]['evidence'].append(f\"Keyword: {keyword}\")\n",
    "    \n",
    "    # Check phrases\n",
    "    for _, row in topic_data['topic_phrases'].iterrows():\n",
    "        phrase = row['phrase'].lower()\n",
    "        topic = row['topic']\n",
    "        debug_info['phrases_checked'] += 1\n",
    "        \n",
    "        if f\" {phrase} \" in f\" {text} \":\n",
    "            debug_info['phrases_found'] += 1\n",
    "            topics_found[topic]['count'] += 1\n",
    "            topics_found[topic]['evidence'].append(f\"Phrase: {phrase}\")\n",
    "    \n",
    "    # Prepare results without applying a minimum threshold\n",
    "    results = {}\n",
    "    for topic, data in topics_found.items():\n",
    "        if data['count'] > 0:  # Include all topics with at least one match\n",
    "            results[topic] = data\n",
    "    \n",
    "    # Periodically print debug information\n",
    "    if random.random() < 0.01:  # Print for ~1% of speeches\n",
    "        print(\"\\nTopic Analysis Debug Info:\")\n",
    "        print(f\"Text length: {len(text.split())} words\")\n",
    "        print(f\"Keywords checked: {debug_info['keywords_checked']}\")\n",
    "        print(f\"Keywords found: {debug_info['keywords_found']}\")\n",
    "        print(f\"Phrases checked: {debug_info['phrases_checked']}\")\n",
    "        print(f\"Phrases found: {debug_info['phrases_found']}\")\n",
    "        print(f\"False matches: {debug_info['false_matches']}\")\n",
    "        print(f\"Topics found: {len(results)}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_topics_over_time(df, topic_data):\n",
    "    \"\"\"\n",
    "    Analyze how topics change over time with detailed debugging\n",
    "    \"\"\"\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')\n",
    "    df['month'] = df['date'].dt.to_period('M')\n",
    "    \n",
    "    topic_time_series = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    # Add debug counters\n",
    "    total_processed = 0\n",
    "    speeches_with_topics = 0\n",
    "    topic_counts = defaultdict(int)\n",
    "    \n",
    "    print(\"\\nStarting topic analysis over time...\")\n",
    "    print(\"Sample of keywords:\", list(topic_data['keywords']['phrase'])[:5])\n",
    "    print(\"Sample of topic phrases:\", list(topic_data['topic_phrases']['phrase'])[:5])\n",
    "    \n",
    "    # Process speeches\n",
    "    for idx, row in df.iterrows():\n",
    "        if idx > 2000:  # Limit for testing\n",
    "            break\n",
    "            \n",
    "        if idx % 100 == 0:  # Progress indicator\n",
    "            print(f\"Processing speech {idx}/2000\")\n",
    "            print(f\"Found topics in {speeches_with_topics}/{total_processed} speeches\")\n",
    "            print(\"Current topic counts:\", dict(topic_counts))\n",
    "        \n",
    "        total_processed += 1\n",
    "        topics = analyze_speech_topics(row['speech_text'], topic_data)\n",
    "        \n",
    "        if topics:\n",
    "            speeches_with_topics += 1\n",
    "            month = row['month']\n",
    "            for topic in topics:\n",
    "                topic_time_series[topic][month] += 1\n",
    "                topic_counts[topic] += 1\n",
    "                \n",
    "        # Debug: Print sample of speeches without topics periodically\n",
    "        if idx % 1000 == 0 and not topics:\n",
    "            print(\"\\nExample of speech without topics:\")\n",
    "            print(\"Speech text excerpt:\", row['speech_text'][:200])\n",
    "            print(\"Speech length:\", len(row['speech_text'].split()))\n",
    "    \n",
    "    # Print final statistics\n",
    "    print(\"\\nTopic Analysis Summary:\")\n",
    "    print(f\"Total speeches processed: {total_processed}\")\n",
    "    print(f\"Speeches with topics: {speeches_with_topics}\")\n",
    "    print(f\"Detection rate: {(speeches_with_topics/total_processed)*100:.2f}%\")\n",
    "    print(\"\\nTopic frequencies:\")\n",
    "    for topic, count in topic_counts.items():\n",
    "        print(f\"{topic}: {count}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    time_series_df = pd.DataFrame(topic_time_series)\n",
    "    \n",
    "    # Debug: Print shape and sample of DataFrame\n",
    "    print(\"\\nTime series DataFrame shape:\", time_series_df.shape)\n",
    "    print(\"Time series columns:\", time_series_df.columns.tolist())\n",
    "    print(\"\\nSample of time series data:\")\n",
    "    print(time_series_df.head())\n",
    "    \n",
    "    # Plot only if we have data\n",
    "    if not time_series_df.empty:\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        for topic in time_series_df.columns:\n",
    "            plt.plot(range(len(time_series_df)), time_series_df[topic], label=topic)\n",
    "        \n",
    "        plt.title('Topic Frequency Over Time')\n",
    "        plt.xlabel('Months')\n",
    "        plt.ylabel('Number of Speeches')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nWarning: No topic data to plot\")\n",
    "    \n",
    "    return time_series_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_party_topic_distribution(df, topic_data):\n",
    "    \"\"\"\n",
    "    Analyze topic distribution across parties\n",
    "    \"\"\"\n",
    "    if 'party' not in df.columns:\n",
    "        print(\"Warning: No party information available\")\n",
    "        return None\n",
    "    \n",
    "    party_topic_counts = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    # Process each speech\n",
    "    for idx, row in df.iterrows():\n",
    "        # break at 2000\n",
    "        if idx == 2000:\n",
    "            break\n",
    "        if idx % 1000 == 0:\n",
    "            print(f\"Processing speech {idx}/2000\")\n",
    "            \n",
    "        topics = analyze_speech_topics(row['speech_text'], topic_data)\n",
    "        party = row['party']\n",
    "        \n",
    "        for topic in topics:\n",
    "            party_topic_counts[party][topic] += 1\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    party_topic_df = pd.DataFrame(party_topic_counts)\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(party_topic_df, annot=True, fmt='g', cmap='YlOrRd')\n",
    "    plt.title('Topic Distribution Across Parties')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return party_topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_speech_topic_mapping(df, topic_data, output_file='speech_topic_mapping.csv'):\n",
    "    \"\"\"\n",
    "    Map each speech ID to detected topics and save as a CSV file.\n",
    "    \"\"\"\n",
    "    mapping = []\n",
    "\n",
    "    print(\"\\nMapping topics to speeches...\")\n",
    "    for idx, row in df.iterrows():\n",
    "        # break at 2000\n",
    "        if idx == 2000:\n",
    "            break\n",
    "        topics = analyze_speech_topics(row['speech_text'], topic_data)\n",
    "        topics_list = list(topics.keys()) if topics else []\n",
    "        mapping.append({\n",
    "            'speech_id': row['speech_id'],\n",
    "            'topics': ', '.join(topics_list) if topics_list else 'None'\n",
    "        })\n",
    "        if idx % 1000 == 0:  # Progress indicator\n",
    "            print(f\"Processed {idx}/2000 speeches...\")\n",
    "\n",
    "    # Convert mapping to DataFrame\n",
    "    topic_mapping_df = pd.DataFrame(mapping)\n",
    "\n",
    "    # Save to CSV\n",
    "    topic_mapping_df.to_csv(output_file, index=False)\n",
    "    print(f\"Speech-to-topic mapping saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load data for multiple congresses\n",
    "    congress_numbers = ['113', '114']\n",
    "    all_data = []\n",
    "    \n",
    "    for congress in congress_numbers:\n",
    "        print(f\"\\nProcessing Congress {congress}\")\n",
    "        df = load_speech_data(congress)\n",
    "        if df is not None:\n",
    "            print(f\"Successfully loaded Congress {congress} data\")\n",
    "            all_data.append(df)\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"\\nNo data was successfully loaded.\")\n",
    "        return\n",
    "    \n",
    "    # Combine the data\n",
    "    print(\"\\nCombining data from all congresses...\")\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Proceed with the rest of your analyses\n",
    "    print(\"\\nDataset Overview:\")\n",
    "    print(f\"Total number of speeches: {len(combined_df)}\")\n",
    "    print(\"\\nColumns available:\", combined_df.columns.tolist())\n",
    "    print(\"\\nMissing values:\\n\", combined_df.isnull().sum())\n",
    "    \n",
    "    # Speech length analysis\n",
    "    print(\"\\nSpeech Length Analysis:\")\n",
    "    length_stats = analyze_speech_lengths(combined_df)\n",
    "    print(\"Length statistics:\")\n",
    "    for key, value in length_stats.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Sample of different length speeches\n",
    "    print(\"\\nSample of shortest speeches:\")\n",
    "    print(combined_df.nsmallest(3, 'word_count')[['speech_text', 'word_count', 'party']])\n",
    "    \n",
    "    print(\"\\nSample of median-length speeches:\")\n",
    "    median_length = combined_df['word_count'].median()\n",
    "    median_speeches = combined_df.iloc[(combined_df['word_count'] - median_length).abs().argsort()[:3]]\n",
    "    print(median_speeches[['speech_text', 'word_count', 'party']])\n",
    "    \n",
    "    # Topic analysis\n",
    "    print(\"\\nLoading and analyzing topics...\")\n",
    "    topic_data = load_topic_files()\n",
    "    \n",
    "    if topic_data is not None:\n",
    "        # Analyze sample of speeches for topics\n",
    "        print(\"\\nAnalyzing topics in sample speeches:\")\n",
    "        sample_size = 5\n",
    "        sample_speeches = combined_df.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "        for _, speech in sample_speeches.iterrows():\n",
    "            print(f\"\\nSpeech ID: {speech['speech_id']}\")\n",
    "            print(f\"Party: {speech.get('party', 'Unknown')}\")\n",
    "            print(f\"Word count: {speech['word_count']}\")\n",
    "            print(\"Excerpt:\", speech['speech_text'][:200], \"...\")\n",
    "            \n",
    "            topics = analyze_speech_topics(speech['speech_text'], topic_data)\n",
    "            if topics:\n",
    "                print(\"Topics found:\")\n",
    "                for topic, details in topics.items():\n",
    "                    print(f\"- {topic}: {details['count']} matches\")\n",
    "                    print(f\"  Evidence: {', '.join(details['evidence'][:3])}\")\n",
    "            else:\n",
    "                print(\"No topics met the threshold criteria\")\n",
    "        \n",
    "        # Temporal analysis of topics\n",
    "        print(\"\\nAnalyzing topic trends over time...\")\n",
    "        time_series_df = analyze_topics_over_time(combined_df, topic_data)\n",
    "\n",
    "        print(\"\\nSaving speech-to-topic mapping...\")\n",
    "        save_speech_topic_mapping(combined_df, topic_data, output_file='speech_topic_mapping.csv')\n",
    "        \n",
    "        # Save time series data\n",
    "        time_series_df.to_csv('topic_time_series.csv')\n",
    "        print(\"Time series data saved to topic_time_series.csv\")\n",
    "        \n",
    "        # Party-topic distribution\n",
    "        print(\"\\nAnalyzing topic distribution across parties...\")\n",
    "        party_topic_df = analyze_party_topic_distribution(combined_df, topic_data)\n",
    "        \n",
    "        if party_topic_df is not None:\n",
    "            # Save party-topic distribution\n",
    "            party_topic_df.to_csv('party_topic_distribution.csv')\n",
    "            print(\"Party-topic distribution saved to party_topic_distribution.csv\")\n",
    "            \n",
    "            # Print summary statistics\n",
    "            print(\"\\nTop topics by party:\")\n",
    "            for party in party_topic_df.columns:\n",
    "                top_topics = party_topic_df[party].nlargest(3)\n",
    "                print(f\"\\n{party}:\")\n",
    "                for topic, count in top_topics.items():\n",
    "                    print(f\"- {topic}: {count} speeches\")\n",
    "    \n",
    "    # Additional temporal analysis\n",
    "    print(\"\\nAnalyzing speech patterns over time...\")\n",
    "    combined_df['date'] = pd.to_datetime(combined_df['date'], format='%Y%m%d')\n",
    "    combined_df['month'] = combined_df['date'].dt.to_period('M')\n",
    "    \n",
    "    # Monthly speech counts\n",
    "    monthly_counts = combined_df.groupby('month').size()\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    monthly_counts.plot(kind='line')\n",
    "    plt.title('Number of Speeches per Month')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Number of Speeches')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Average speech length over time\n",
    "    monthly_lengths = combined_df.groupby('month')['word_count'].mean()\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    monthly_lengths.plot(kind='line')\n",
    "    plt.title('Average Speech Length over Time')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Average Word Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save processed data\n",
    "    print(\"\\nSaving processed data...\")\n",
    "    \n",
    "    # Save basic statistics\n",
    "    stats_summary = {\n",
    "        'total_speeches': len(combined_df),\n",
    "        'unique_speakers': combined_df['speaker'].nunique(),\n",
    "        'date_range': f\"{combined_df['date'].min()} to {combined_df['date'].max()}\",\n",
    "        'length_stats': length_stats,\n",
    "    }\n",
    "    \n",
    "    if party_stats is not None:\n",
    "        stats_summary['party_distribution'] = party_stats.to_dict()\n",
    "    \n",
    "    # Convert to DataFrame for easy CSV export\n",
    "    stats_df = pd.DataFrame([stats_summary])\n",
    "    stats_df.to_csv('speech_analysis_summary.csv')\n",
    "    print(\"Analysis summary saved to speech_analysis_summary.csv\")\n",
    "    \n",
    "    # Save sample of speeches with their topics\n",
    "    if topic_data is not None:\n",
    "        print(\"\\nSaving sample speeches with topic analysis...\")\n",
    "        sample_size = min(1000, len(combined_df))\n",
    "        sample_with_topics = combined_df.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "        topic_results = []\n",
    "        for _, speech in sample_with_topics.iterrows():\n",
    "            topics = analyze_speech_topics(speech['speech_text'], topic_data)\n",
    "            result = {\n",
    "                'speech_id': speech['speech_id'],\n",
    "                'party': speech.get('party', 'Unknown'),\n",
    "                'date': speech['date'],\n",
    "                'word_count': speech['word_count'],\n",
    "                'topics_found': ','.join(topics.keys()) if topics else 'None'\n",
    "            }\n",
    "            topic_results.append(result)\n",
    "        \n",
    "        topic_analysis_df = pd.DataFrame(topic_results)\n",
    "        topic_analysis_df.to_csv('speech_topic_samples.csv', index=False)\n",
    "        print(\"Sample speeches with topics saved to speech_topic_samples.csv\")\n",
    "    \n",
    "    print(\"\\nAnalysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Congress 113\n",
      "\n",
      "Congress 113 data summary:\n",
      "Number of speeches: 12813\n",
      "Number of descriptions: 128148\n",
      "\n",
      "Data types in speech_df:\n",
      "speech_id      object\n",
      "speech_text    object\n",
      "dtype: object\n",
      "\n",
      "Data types in desc_df:\n",
      "speech_id             object\n",
      "chamber               object\n",
      "date                  object\n",
      "number_within_file     int64\n",
      "speaker               object\n",
      "first_name            object\n",
      "last_name             object\n",
      "state                 object\n",
      "gender                object\n",
      "line_start            object\n",
      "line_end              object\n",
      "file                  object\n",
      "char_count             int64\n",
      "word_count             int64\n",
      "dtype: object\n",
      "\n",
      "Checking for null speech_ids:\n",
      "Null speech_ids in speech_df: 0\n",
      "Null speech_ids in desc_df: 0\n",
      "\n",
      "Checking for duplicate speech_ids:\n",
      "Duplicate speech_ids in speech_df: 0\n",
      "Duplicate speech_ids in desc_df: 0\n",
      "\n",
      "Number of speeches after merge: 12813\n",
      "\n",
      "Attempting to load SpeakerMap file: ../small_speech_data/113_SpeakerMap.txt\n",
      "SpeakerMap headers: ['speakerid', 'speech_id', 'lastname', 'firstname', 'chamber', 'state', 'gender', 'party', 'district', 'nonvoting']\n",
      "Loaded SpeakerMap data: 77621 rows\n",
      "\n",
      "Party information summary:\n",
      "party\n",
      "NaN    5053\n",
      "D      4374\n",
      "R      3369\n",
      "I        17\n",
      "Name: count, dtype: int64\n",
      "Successfully loaded Congress 113 data\n",
      "\n",
      "Processing Congress 114\n",
      "\n",
      "Congress 114 data summary:\n",
      "Number of speeches: 11228\n",
      "Number of descriptions: 112290\n",
      "\n",
      "Data types in speech_df:\n",
      "speech_id      object\n",
      "speech_text    object\n",
      "dtype: object\n",
      "\n",
      "Data types in desc_df:\n",
      "speech_id             object\n",
      "chamber               object\n",
      "date                  object\n",
      "number_within_file     int64\n",
      "speaker               object\n",
      "first_name            object\n",
      "last_name             object\n",
      "state                 object\n",
      "gender                object\n",
      "line_start            object\n",
      "line_end              object\n",
      "file                  object\n",
      "char_count             int64\n",
      "word_count             int64\n",
      "dtype: object\n",
      "\n",
      "Checking for null speech_ids:\n",
      "Null speech_ids in speech_df: 0\n",
      "Null speech_ids in desc_df: 0\n",
      "\n",
      "Checking for duplicate speech_ids:\n",
      "Duplicate speech_ids in speech_df: 0\n",
      "Duplicate speech_ids in desc_df: 0\n",
      "\n",
      "Number of speeches after merge: 11228\n",
      "\n",
      "Attempting to load SpeakerMap file: ../small_speech_data/114_SpeakerMap.txt\n",
      "SpeakerMap headers: ['speakerid', 'speech_id', 'lastname', 'firstname', 'chamber', 'state', 'gender', 'party', 'district', 'nonvoting']\n",
      "Loaded SpeakerMap data: 67971 rows\n",
      "\n",
      "Party information summary:\n",
      "party\n",
      "NaN    4143\n",
      "R      3806\n",
      "D      3233\n",
      "I        46\n",
      "Name: count, dtype: int64\n",
      "Successfully loaded Congress 114 data\n",
      "\n",
      "Combining data from all congresses...\n",
      "\n",
      "Dataset Overview:\n",
      "Total number of speeches: 24041\n",
      "\n",
      "Columns available: ['speech_id', 'speech_text', 'chamber', 'date', 'number_within_file', 'speaker', 'first_name', 'last_name', 'state', 'gender', 'line_start', 'line_end', 'file', 'char_count', 'word_count', 'party']\n",
      "\n",
      "Missing values:\n",
      " speech_id                0\n",
      "speech_text              0\n",
      "chamber                 13\n",
      "date                     0\n",
      "number_within_file       0\n",
      "speaker                  0\n",
      "first_name               0\n",
      "last_name                0\n",
      "state                    0\n",
      "gender                   0\n",
      "line_start               0\n",
      "line_end                 0\n",
      "file                     0\n",
      "char_count               0\n",
      "word_count               0\n",
      "party                 9196\n",
      "dtype: int64\n",
      "\n",
      "Speech Length Analysis:\n",
      "Word count ranges:\n",
      "0-50: 13708\n",
      "50-100: 1401\n",
      "100-150: 1099\n",
      "150-200: 1400\n",
      "200-250: 1024\n",
      "250-300: 716\n",
      "300-350: 694\n",
      "350-400: 545\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length statistics:\n",
      "mean_length: 201.82821014100912\n",
      "median_length: 30.0\n",
      "std_length: 461.9561056333619\n",
      "min_length: 1\n",
      "max_length: 21422\n",
      "quartiles: {0.25: 10.0, 0.5: 30.0, 0.75: 219.0}\n",
      "\n",
      "Sample of shortest speeches:\n",
      "          speech_text  word_count party\n",
      "26   Congratulations.           1   NaN\n",
      "143          Maryland           1     D\n",
      "145             Texas           1   NaN\n",
      "\n",
      "Sample of median-length speeches:\n",
      "                                            speech_text  word_count party\n",
      "4560  Pursuant to clause 12(a) of rule I. the Chair ...          30   NaN\n",
      "5991  Pursuant to clause 12(a) of rule I. the Chair ...          30   NaN\n",
      "4828  I appreciate the question from the Senator fro...          30     R\n",
      "\n",
      "Loading and analyzing topics...\n",
      "Warning: Skipping malformed line 48: budget|revenu increasbusiness|order accommod\n",
      "Warning: Skipping malformed line 197: crime|war crimindefense|alarm rate\n",
      "Warning: Skipping malformed line 733: elections|produc electrenvironment|lake area\n",
      "Warning: Skipping malformed line 1997: labor|union nationmail|.\n",
      "\n",
      "Topic Validation:\n",
      "Expected topics: 22\n",
      "Found topics: 23\n",
      "Missing topics: set()\n",
      "Extra topics: {'topic'}\n",
      "\n",
      "Data Summary:\n",
      "Topic phrases: 7556\n",
      "Keywords: 297\n",
      "False matches: 3009\n",
      "\n",
      "Analyzing topics in sample speeches:\n",
      "\n",
      "Speech ID: 1140004827\n",
      "Party: R\n",
      "Word count: 148\n",
      "Excerpt: Mr. Speaker. last week in his State of the Union Address. President Obama proposed to fund publicly the first 2 years of community college for all Americans. As a former community college president. I ...\n",
      "Topics found:\n",
      "- budget: 1 matches\n",
      "  Evidence: Keyword: budget\n",
      "- federalism: 3 matches\n",
      "  Evidence: Keyword: state, Keyword: union, Phrase: union address\n",
      "\n",
      "Speech ID: 1130011611\n",
      "Party: nan\n",
      "Word count: 10\n",
      "Excerpt: The question is on the Speakers approval of the Journal. ...\n",
      "No topics met the threshold criteria\n",
      "\n",
      "Speech ID: 1140005952\n",
      "Party: R\n",
      "Word count: 134\n",
      "Excerpt: Mr. President. the Senator from Virginia. Mr. WARNER. and I are offering an amendment that would help school officials to learn about existing Federal programs to improve energy efficiency in order to ...\n",
      "Topics found:\n",
      "- education: 2 matches\n",
      "  Evidence: Keyword: school, Phrase: help school\n",
      "- elections: 1 matches\n",
      "  Evidence: Keyword: vote\n",
      "\n",
      "Speech ID: 1140005990\n",
      "Party: nan\n",
      "Word count: 4\n",
      "Excerpt: The Senator from Alaska. ...\n",
      "No topics met the threshold criteria\n",
      "\n",
      "Speech ID: 1130005972\n",
      "Party: D\n",
      "Word count: 935\n",
      "Excerpt: Madam Speaker. it just came over the newswire a few minutes ago that on Friday morning. March 1. there will be a meeting at the White House involving President Obama. the leadership of the House. Spea ...\n",
      "Topics found:\n",
      "- budget: 3 matches\n",
      "  Evidence: Keyword: budget, Keyword: debt, Phrase: budget control\n",
      "- business: 1 matches\n",
      "  Evidence: Keyword: oil\n",
      "- justice: 2 matches\n",
      "  Evidence: Keyword: right, Phrase: year right\n",
      "- labor: 1 matches\n",
      "  Evidence: Phrase: direct payment\n",
      "- money: 1 matches\n",
      "  Evidence: Phrase: payment system\n",
      "\n",
      "Analyzing topic trends over time...\n",
      "\n",
      "Starting topic analysis over time...\n",
      "Sample of keywords: ['phrase', 'alcohol', 'antisaloon', 'distil', 'liquor']\n",
      "Sample of topic phrases: ['phrase', 'abus alcohol', 'alcohol abus', 'alcohol beverag', 'alcohol content']\n",
      "Processing speech 0/2000\n",
      "Found topics in 0/0 speeches\n",
      "Current topic counts: {}\n",
      "\n",
      "Example of speech without topics:\n",
      "Speech text excerpt: The Representativeselect and their guests will please remain standing and join in the Pledge of Allegiance.\n",
      "Speech length: 16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 70\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Temporal analysis of topics\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnalyzing topic trends over time...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m time_series_df \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_topics_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSaving speech-to-topic mapping...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m save_speech_topic_mapping(combined_df, topic_data, output_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeech_topic_mapping.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 30\u001b[0m, in \u001b[0;36manalyze_topics_over_time\u001b[0;34m(df, topic_data)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent topic counts:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mdict\u001b[39m(topic_counts))\n\u001b[1;32m     29\u001b[0m total_processed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 30\u001b[0m topics \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_speech_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspeech_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m topics:\n\u001b[1;32m     33\u001b[0m     speeches_with_topics \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[8], line 43\u001b[0m, in \u001b[0;36manalyze_speech_topics\u001b[0;34m(speech_text, topic_data)\u001b[0m\n\u001b[1;32m     40\u001b[0m             topics_found[topic][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevidence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeyword: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Check phrases\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtopic_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtopic_phrases\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mphrase\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtopic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MIT Fall 2024 Classes/6.8611/Project/NLP-Frameshifting/myenv/lib/python3.12/site-packages/pandas/core/frame.py:1554\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1552\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m-> 1554\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[1;32m   1556\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/MIT Fall 2024 Classes/6.8611/Project/NLP-Frameshifting/myenv/lib/python3.12/site-packages/pandas/core/series.py:584\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    582\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/MIT Fall 2024 Classes/6.8611/Project/NLP-Frameshifting/myenv/lib/python3.12/site-packages/pandas/core/construction.py:555\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    552\u001b[0m     object_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;66;03m# extract ndarray or ExtensionArray, ensure we have no NumpyExtensionArray\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/MIT Fall 2024 Classes/6.8611/Project/NLP-Frameshifting/myenv/lib/python3.12/site-packages/pandas/core/construction.py:416\u001b[0m, in \u001b[0;36mextract_array\u001b[0;34m(obj, extract_numpy, extract_range)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_array\u001b[39m(\n\u001b[1;32m    411\u001b[0m     obj: T, extract_numpy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, extract_range: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    412\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T \u001b[38;5;241m|\u001b[39m ArrayLike:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m--> 416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_array\u001b[39m(\n\u001b[1;32m    417\u001b[0m     obj: T, extract_numpy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, extract_range: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    418\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T \u001b[38;5;241m|\u001b[39m ArrayLike:\n\u001b[1;32m    419\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m    Extract the ndarray or ExtensionArray from a Series or Index.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m    array([1, 2, 3])\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     typ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_typ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
