{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original graphs recreation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreating all plots...\n",
      "1. Recreating party trends...\n",
      "2. Recreating issue trends...\n",
      "3. Recreating polarization trends...\n",
      "4. Recreating issue heatmaps...\n",
      "\n",
      "All plots have been recreated successfully!\n",
      "Output directory: recreated_plots\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List\n",
    "\n",
    "class PlotRecreator:\n",
    "    def __init__(self, data_dir: str = 'analysis_results'):\n",
    "        \"\"\"Initialize the plot recreator with the data directory\"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        # Load all data files\n",
    "        with open(os.path.join(data_dir, 'raw_speech_data.json'), 'r') as f:\n",
    "            self.raw_data = json.load(f)\n",
    "            \n",
    "        with open(os.path.join(data_dir, 'trend_data.json'), 'r') as f:\n",
    "            self.trend_data = json.load(f)\n",
    "            \n",
    "        with open(os.path.join(data_dir, 'polarization_data.json'), 'r') as f:\n",
    "            self.polarization_data = json.load(f)\n",
    "            \n",
    "        with open(os.path.join(data_dir, 'metadata.json'), 'r') as f:\n",
    "            self.metadata = json.load(f)\n",
    "        \n",
    "        # Convert raw data to DataFrames\n",
    "        self.raw_dfs = {\n",
    "            congress: pd.DataFrame(data) \n",
    "            for congress, data in self.raw_data.items()\n",
    "        }\n",
    "    \n",
    "    def recreate_party_trends(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate party-level trend plots\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Emotional Intensity by Party\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for party in ['D', 'R']:\n",
    "            df = pd.DataFrame(self.trend_data['by_party'][party])\n",
    "            plt.plot(df['congress'], df['emotional_avg'], \n",
    "                    label=f\"{'Democratic' if party == 'D' else 'Republican'}\")\n",
    "            plt.fill_between(df['congress'],\n",
    "                           df['emotional_avg'] - df['emotional_std'],\n",
    "                           df['emotional_avg'] + df['emotional_std'],\n",
    "                           alpha=0.2)\n",
    "        \n",
    "        plt.title('Emotional Intensity by Party Over Time')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Average Emotional Intensity')\n",
    "        plt.ylim(1, 5)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{save_dir}/emotional_intensity_by_party.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Political Spectrum by Party\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for party in ['D', 'R']:\n",
    "            df = pd.DataFrame(self.trend_data['by_party'][party])\n",
    "            plt.plot(df['congress'], df['political_avg'],\n",
    "                    label=f\"{'Democratic' if party == 'D' else 'Republican'}\")\n",
    "            plt.fill_between(df['congress'],\n",
    "                           df['political_avg'] - df['political_std'],\n",
    "                           df['political_avg'] + df['political_std'],\n",
    "                           alpha=0.2)\n",
    "        \n",
    "        plt.title('Political Spectrum Position by Party Over Time')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Average Political Spectrum Position')\n",
    "        plt.ylim(1, 5)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{save_dir}/political_spectrum_by_party.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def recreate_issue_trends(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate issue-level trend plots\"\"\"\n",
    "        base_dir = os.path.join(save_dir, 'issues')\n",
    "        os.makedirs(base_dir, exist_ok=True)\n",
    "        \n",
    "        for issue in self.metadata['valid_issues']:\n",
    "            issue_dir = os.path.join(base_dir, issue.lower().replace(' ', '_'))\n",
    "            os.makedirs(issue_dir, exist_ok=True)\n",
    "            \n",
    "            # Emotional Intensity\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            for party in ['D', 'R']:\n",
    "                if issue in self.trend_data['by_party_issue'] and \\\n",
    "                party in self.trend_data['by_party_issue'][issue]:\n",
    "                    df = pd.DataFrame(self.trend_data['by_party_issue'][issue][party])\n",
    "                    plt.plot(df['congress'], df['emotional_avg'],\n",
    "                            label=f\"{'Democratic' if party == 'D' else 'Republican'}\")\n",
    "                    plt.fill_between(df['congress'],\n",
    "                                   df['emotional_avg'] - df['emotional_std'],\n",
    "                                   df['emotional_avg'] + df['emotional_std'],\n",
    "                                   alpha=0.2)\n",
    "            \n",
    "            plt.title(f'Emotional Intensity Over Time: {issue}')\n",
    "            plt.xlabel('Congress')\n",
    "            plt.ylabel('Average Emotional Intensity')\n",
    "            plt.ylim(1, 5)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(f\"{issue_dir}/emotional_intensity.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            # Political Spectrum\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            for party in ['D', 'R']:\n",
    "                if issue in self.trend_data['by_party_issue'] and \\\n",
    "                party in self.trend_data['by_party_issue'][issue]:\n",
    "                    df = pd.DataFrame(self.trend_data['by_party_issue'][issue][party])\n",
    "                    plt.plot(df['congress'], df['political_avg'],\n",
    "                            label=f\"{'Democratic' if party == 'D' else 'Republican'}\")\n",
    "                    plt.fill_between(df['congress'],\n",
    "                                   df['political_avg'] - df['political_std'],\n",
    "                                   df['political_avg'] + df['political_std'],\n",
    "                                   alpha=0.2)\n",
    "            \n",
    "            plt.title(f'Political Spectrum Position Over Time: {issue}')\n",
    "            plt.xlabel('Congress')\n",
    "            plt.ylabel('Average Political Spectrum Position')\n",
    "            plt.ylim(1, 5)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(f\"{issue_dir}/political_spectrum.png\")\n",
    "            plt.close()\n",
    "    \n",
    "    def recreate_polarization_trends(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate polarization trend plots\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        df = pd.DataFrame(self.polarization_data['overall'])\n",
    "        plt.plot(df['congress'], df['emotional_gap'], label='Emotional Gap')\n",
    "        plt.plot(df['congress'], df['political_gap'], label='Political Gap')\n",
    "        plt.title('Party Polarization Over Time')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Party Gap')\n",
    "        plt.ylim(-4, 4)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{save_dir}/overall_polarization.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def recreate_issue_heatmaps(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate issue heatmaps\"\"\"\n",
    "        heatmap_dir = os.path.join(save_dir, 'issue_heatmaps')\n",
    "        os.makedirs(heatmap_dir, exist_ok=True)\n",
    "        \n",
    "        # Get all congresses and issues\n",
    "        congresses = sorted(self.raw_data.keys(), key=int)\n",
    "        issues = list(self.metadata['valid_issues'])\n",
    "        \n",
    "        # Initialize matrices\n",
    "        prevalence_matrix = np.zeros((len(issues), len(congresses)))\n",
    "        emotional_matrix = np.zeros((len(issues), len(congresses)))\n",
    "        political_matrix = np.zeros((len(issues), len(congresses)))\n",
    "        \n",
    "        # Fill matrices using raw data\n",
    "        for i, issue in enumerate(issues):\n",
    "            for j, congress in enumerate(congresses):\n",
    "                df = pd.DataFrame(self.raw_data[congress])\n",
    "                # Find the LABEL that maps to this issue\n",
    "                issue_label = [k for k, v in self.metadata['issue_map'].items() if v == issue][0]\n",
    "                issue_mask = df['issues'].apply(lambda x: issue_label in x)\n",
    "                issue_df = df[issue_mask]\n",
    "                \n",
    "                if not issue_df.empty:\n",
    "                    prevalence_matrix[i, j] = len(issue_df) / len(df) * 100\n",
    "                    emotional_matrix[i, j] = issue_df['emotional_intensity'].mean()\n",
    "                    political_matrix[i, j] = issue_df['political_spectrum'].mean()\n",
    "        \n",
    "        # Plot heatmaps\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        sns.heatmap(prevalence_matrix,\n",
    "                    xticklabels=congresses,\n",
    "                    yticklabels=issues,\n",
    "                    cmap='YlOrRd',\n",
    "                    annot=True,\n",
    "                    fmt='.1f')\n",
    "        plt.title('Issue Prevalence Over Time (%)')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Issue')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{heatmap_dir}/issue_prevalence.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        sns.heatmap(emotional_matrix,\n",
    "                    xticklabels=congresses,\n",
    "                    yticklabels=issues,\n",
    "                    cmap='Purples',\n",
    "                    annot=True,\n",
    "                    fmt='.2f',\n",
    "                    vmin=1, vmax=5)\n",
    "        plt.title('Average Emotional Intensity by Issue Over Time')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Issue')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{heatmap_dir}/issue_emotional.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        sns.heatmap(political_matrix,\n",
    "                    xticklabels=congresses,\n",
    "                    yticklabels=issues,\n",
    "                    cmap='RdBu_r',\n",
    "                    annot=True,\n",
    "                    fmt='.2f',\n",
    "                    vmin=1, vmax=5)\n",
    "        plt.title('Average Political Position by Issue Over Time')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Issue')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{heatmap_dir}/issue_political.png\")\n",
    "        plt.close()\n",
    "\n",
    "    def recreate_all_plots(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate all plots\"\"\"\n",
    "        print(\"Recreating all plots...\")\n",
    "        \n",
    "        # Create main directory\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Recreate each type of plot\n",
    "        print(\"1. Recreating party trends...\")\n",
    "        self.recreate_party_trends(save_dir)\n",
    "        \n",
    "        print(\"2. Recreating issue trends...\")\n",
    "        self.recreate_issue_trends(save_dir)\n",
    "        \n",
    "        print(\"3. Recreating polarization trends...\")\n",
    "        self.recreate_polarization_trends(save_dir)\n",
    "        \n",
    "        print(\"4. Recreating issue heatmaps...\")\n",
    "        self.recreate_issue_heatmaps(save_dir)\n",
    "        \n",
    "        print(\"\\nAll plots have been recreated successfully!\")\n",
    "        print(f\"Output directory: {save_dir}\")\n",
    "\n",
    "def main():\n",
    "    # Initialize the plot recreator\n",
    "    recreator = PlotRecreator(data_dir='analysis_results')\n",
    "    \n",
    "    # Recreate all plots\n",
    "    recreator.recreate_all_plots(save_dir='recreated_plots')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### graphs recreation with no standard deviation shading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreating all plots...\n",
      "1. Recreating party trends...\n",
      "2. Recreating issue trends...\n",
      "3. Recreating polarization trends...\n",
      "4. Recreating issue heatmaps...\n",
      "\n",
      "All plots have been recreated successfully!\n",
      "Output directory: recreated_plots\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List\n",
    "\n",
    "class PlotRecreator:\n",
    "    def __init__(self, data_dir: str = 'analysis_results'):\n",
    "        \"\"\"Initialize the plot recreator with the data directory\"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        # Load all data files\n",
    "        with open(os.path.join(data_dir, 'raw_speech_data.json'), 'r') as f:\n",
    "            self.raw_data = json.load(f)\n",
    "            \n",
    "        with open(os.path.join(data_dir, 'trend_data.json'), 'r') as f:\n",
    "            self.trend_data = json.load(f)\n",
    "            \n",
    "        with open(os.path.join(data_dir, 'polarization_data.json'), 'r') as f:\n",
    "            self.polarization_data = json.load(f)\n",
    "            \n",
    "        with open(os.path.join(data_dir, 'metadata.json'), 'r') as f:\n",
    "            self.metadata = json.load(f)\n",
    "        \n",
    "        # Convert raw data to DataFrames\n",
    "        self.raw_dfs = {\n",
    "            congress: pd.DataFrame(data) \n",
    "            for congress, data in self.raw_data.items()\n",
    "        }\n",
    "    \n",
    "    def recreate_party_trends(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate party-level trend plots\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Emotional Intensity by Party\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for party in ['D', 'R']:\n",
    "            df = pd.DataFrame(self.trend_data['by_party'][party])\n",
    "            plt.plot(df['congress'], df['emotional_avg'], \n",
    "                    label=f\"{'Democratic' if party == 'D' else 'Republican'}\")\n",
    "        \n",
    "        plt.title('Emotional Intensity by Party Over Time')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Average Emotional Intensity')\n",
    "        plt.ylim(1, 5)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{save_dir}/emotional_intensity_by_party.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Political Spectrum by Party\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for party in ['D', 'R']:\n",
    "            df = pd.DataFrame(self.trend_data['by_party'][party])\n",
    "            plt.plot(df['congress'], df['political_avg'],\n",
    "                    label=f\"{'Democratic' if party == 'D' else 'Republican'}\")\n",
    "        \n",
    "        plt.title('Political Spectrum Position by Party Over Time')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Average Political Spectrum Position')\n",
    "        plt.ylim(1, 5)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{save_dir}/political_spectrum_by_party.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def recreate_issue_trends(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate issue-level trend plots\"\"\"\n",
    "        base_dir = os.path.join(save_dir, 'issues')\n",
    "        os.makedirs(base_dir, exist_ok=True)\n",
    "        \n",
    "        for issue in self.metadata['valid_issues']:\n",
    "            issue_dir = os.path.join(base_dir, issue.lower().replace(' ', '_'))\n",
    "            os.makedirs(issue_dir, exist_ok=True)\n",
    "            \n",
    "            # Emotional Intensity\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            for party in ['D', 'R']:\n",
    "                if issue in self.trend_data['by_party_issue'] and \\\n",
    "                party in self.trend_data['by_party_issue'][issue]:\n",
    "                    df = pd.DataFrame(self.trend_data['by_party_issue'][issue][party])\n",
    "                    plt.plot(df['congress'], df['emotional_avg'],\n",
    "                            label=f\"{'Democratic' if party == 'D' else 'Republican'}\")\n",
    "            \n",
    "            plt.title(f'Emotional Intensity Over Time: {issue}')\n",
    "            plt.xlabel('Congress')\n",
    "            plt.ylabel('Average Emotional Intensity')\n",
    "            plt.ylim(1, 5)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(f\"{issue_dir}/emotional_intensity.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            # Political Spectrum\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            for party in ['D', 'R']:\n",
    "                if issue in self.trend_data['by_party_issue'] and \\\n",
    "                party in self.trend_data['by_party_issue'][issue]:\n",
    "                    df = pd.DataFrame(self.trend_data['by_party_issue'][issue][party])\n",
    "                    plt.plot(df['congress'], df['political_avg'],\n",
    "                            label=f\"{'Democratic' if party == 'D' else 'Republican'}\")\n",
    "            \n",
    "            plt.title(f'Political Spectrum Position Over Time: {issue}')\n",
    "            plt.xlabel('Congress')\n",
    "            plt.ylabel('Average Political Spectrum Position')\n",
    "            plt.ylim(1, 5)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(f\"{issue_dir}/political_spectrum.png\")\n",
    "            plt.close()\n",
    "    \n",
    "    def recreate_polarization_trends(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate polarization trend plots\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        df = pd.DataFrame(self.polarization_data['overall'])\n",
    "        plt.plot(df['congress'], df['emotional_gap'], label='Emotional Gap')\n",
    "        plt.plot(df['congress'], df['political_gap'], label='Political Gap')\n",
    "        plt.title('Party Polarization Over Time')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Party Gap')\n",
    "        plt.ylim(-4, 4)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{save_dir}/overall_polarization.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def recreate_issue_heatmaps(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate issue heatmaps\"\"\"\n",
    "        heatmap_dir = os.path.join(save_dir, 'issue_heatmaps')\n",
    "        os.makedirs(heatmap_dir, exist_ok=True)\n",
    "        \n",
    "        # Get all congresses and issues\n",
    "        congresses = sorted(self.raw_data.keys(), key=int)\n",
    "        issues = list(self.metadata['valid_issues'])\n",
    "        \n",
    "        # Initialize matrices\n",
    "        prevalence_matrix = np.zeros((len(issues), len(congresses)))\n",
    "        emotional_matrix = np.zeros((len(issues), len(congresses)))\n",
    "        political_matrix = np.zeros((len(issues), len(congresses)))\n",
    "        \n",
    "        # Fill matrices using raw data\n",
    "        for i, issue in enumerate(issues):\n",
    "            for j, congress in enumerate(congresses):\n",
    "                df = pd.DataFrame(self.raw_data[congress])\n",
    "                # Find the LABEL that maps to this issue\n",
    "                issue_label = [k for k, v in self.metadata['issue_map'].items() if v == issue][0]\n",
    "                issue_mask = df['issues'].apply(lambda x: issue_label in x)\n",
    "                issue_df = df[issue_mask]\n",
    "                \n",
    "                if not issue_df.empty:\n",
    "                    prevalence_matrix[i, j] = len(issue_df) / len(df) * 100\n",
    "                    emotional_matrix[i, j] = issue_df['emotional_intensity'].mean()\n",
    "                    political_matrix[i, j] = issue_df['political_spectrum'].mean()\n",
    "        \n",
    "        # Plot heatmaps\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        sns.heatmap(prevalence_matrix,\n",
    "                    xticklabels=congresses,\n",
    "                    yticklabels=issues,\n",
    "                    cmap='YlOrRd',\n",
    "                    annot=True,\n",
    "                    fmt='.1f')\n",
    "        plt.title('Issue Prevalence Over Time (%)')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Issue')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{heatmap_dir}/issue_prevalence.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        sns.heatmap(emotional_matrix,\n",
    "                    xticklabels=congresses,\n",
    "                    yticklabels=issues,\n",
    "                    cmap='RdBu_r',\n",
    "                    annot=True,\n",
    "                    fmt='.2f',\n",
    "                    vmin=1, vmax=5)\n",
    "        plt.title('Average Emotional Intensity by Issue Over Time')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Issue')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{heatmap_dir}/issue_emotional.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        sns.heatmap(political_matrix,\n",
    "                    xticklabels=congresses,\n",
    "                    yticklabels=issues,\n",
    "                    cmap='RdBu_r',\n",
    "                    annot=True,\n",
    "                    fmt='.2f',\n",
    "                    vmin=1, vmax=5)\n",
    "        plt.title('Average Political Position by Issue Over Time')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Issue')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{heatmap_dir}/issue_political.png\")\n",
    "        plt.close()\n",
    "\n",
    "    def recreate_all_plots(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate all plots\"\"\"\n",
    "        print(\"Recreating all plots...\")\n",
    "        \n",
    "        # Create main directory\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Recreate each type of plot\n",
    "        print(\"1. Recreating party trends...\")\n",
    "        self.recreate_party_trends(save_dir)\n",
    "        \n",
    "        print(\"2. Recreating issue trends...\")\n",
    "        self.recreate_issue_trends(save_dir)\n",
    "        \n",
    "        print(\"3. Recreating polarization trends...\")\n",
    "        self.recreate_polarization_trends(save_dir)\n",
    "        \n",
    "        print(\"4. Recreating issue heatmaps...\")\n",
    "        self.recreate_issue_heatmaps(save_dir)\n",
    "        \n",
    "        print(\"\\nAll plots have been recreated successfully!\")\n",
    "        print(f\"Output directory: {save_dir}\")\n",
    "\n",
    "def main():\n",
    "    # Initialize the plot recreator\n",
    "    recreator = PlotRecreator(data_dir='analysis_results')\n",
    "    \n",
    "    # Recreate all plots\n",
    "    recreator.recreate_all_plots(save_dir='recreated_plots')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from typing import Dict, List\n",
    "\n",
    "class PlotRecreator:\n",
    "    def __init__(self, data_dir: str = 'analysis_results'):\n",
    "        \"\"\"Initialize the plot recreator with the data directory\"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        # Load all data files\n",
    "        with open(os.path.join(data_dir, 'raw_speech_data.json'), 'r') as f:\n",
    "            self.raw_data = json.load(f)\n",
    "            \n",
    "        with open(os.path.join(data_dir, 'trend_data.json'), 'r') as f:\n",
    "            self.trend_data = json.load(f)\n",
    "            \n",
    "        with open(os.path.join(data_dir, 'polarization_data.json'), 'r') as f:\n",
    "            self.polarization_data = json.load(f)\n",
    "            \n",
    "        with open(os.path.join(data_dir, 'metadata.json'), 'r') as f:\n",
    "            self.metadata = json.load(f)\n",
    "        \n",
    "        # Convert raw data to DataFrames\n",
    "        self.raw_dfs = {\n",
    "            congress: pd.DataFrame(data) \n",
    "            for congress, data in self.raw_data.items()\n",
    "        }\n",
    "\n",
    "    def plot_issue_evolution_matrix(self, save_dir: str = 'enhanced_plots'):\n",
    "        \"\"\"Create a multi-panel visualization showing issue evolution across all dimensions\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # For each issue, create a 2D scatter plot over time\n",
    "        for issue in self.metadata['valid_issues']:\n",
    "            fig, ax = plt.subplots(figsize=(15, 10))\n",
    "            \n",
    "            # Get data for both parties\n",
    "            for party in ['D', 'R']:\n",
    "                if issue in self.trend_data['by_party_issue'] and \\\n",
    "                   party in self.trend_data['by_party_issue'][issue]:\n",
    "                    df = pd.DataFrame(self.trend_data['by_party_issue'][issue][party])\n",
    "                    \n",
    "                    # Create scatter plot where:\n",
    "                    # X-axis: political_avg\n",
    "                    # Y-axis: emotional_avg\n",
    "                    # Color: congress (for time evolution)\n",
    "                    # Size: count (speech frequency)\n",
    "                    scatter = ax.scatter(\n",
    "                        df['political_avg'],\n",
    "                        df['emotional_avg'],\n",
    "                        c=df['congress'],\n",
    "                        s=df['count']*5,  # Scale size for visibility\n",
    "                        alpha=0.6,\n",
    "                        cmap='coolwarm' if party == 'D' else 'RdYlBu',\n",
    "                        label=f\"{'Democratic' if party == 'D' else 'Republican'}\"\n",
    "                    )\n",
    "                    \n",
    "                    # Add arrows to show direction of movement over time\n",
    "                    for i in range(len(df)-1):\n",
    "                        ax.arrow(\n",
    "                            df['political_avg'].iloc[i],\n",
    "                            df['emotional_avg'].iloc[i],\n",
    "                            df['political_avg'].iloc[i+1] - df['political_avg'].iloc[i],\n",
    "                            df['emotional_avg'].iloc[i+1] - df['emotional_avg'].iloc[i],\n",
    "                            head_width=0.05,\n",
    "                            head_length=0.05,\n",
    "                            fc='gray',\n",
    "                            ec='gray',\n",
    "                            alpha=0.3\n",
    "                        )\n",
    "            \n",
    "            plt.colorbar(scatter, label='Congress')\n",
    "            plt.title(f'Evolution of {issue} Framing (1945-2016)')\n",
    "            plt.xlabel('Political Spectrum Position (Left → Right)')\n",
    "            plt.ylabel('Emotional Intensity (Low → High)')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{save_dir}/{issue.lower().replace(' ', '_')}_evolution.png\")\n",
    "            plt.close()\n",
    "\n",
    "    def plot_party_polarization_trends(self, save_dir: str = 'enhanced_plots'):\n",
    "        \"\"\"Create visualization showing political spectrum polarization over time\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Calculate political spectrum gap between parties for each issue over time\n",
    "        polarization_data = {}\n",
    "        for issue in self.metadata['valid_issues']:\n",
    "            if issue in self.trend_data['by_party_issue']:\n",
    "                dem_data = pd.DataFrame(self.trend_data['by_party_issue'][issue]['D'])\n",
    "                rep_data = pd.DataFrame(self.trend_data['by_party_issue'][issue]['R'])\n",
    "                \n",
    "                # Calculate absolute difference in political spectrum positions\n",
    "                distances = []\n",
    "                congresses = sorted(set(dem_data['congress']) & set(rep_data['congress']))\n",
    "                for congress in congresses:\n",
    "                    dem_point = dem_data[dem_data['congress'] == congress]\n",
    "                    rep_point = rep_data[rep_data['congress'] == congress]\n",
    "                    \n",
    "                    if not dem_point.empty and not rep_point.empty:\n",
    "                        distance = abs(rep_point['political_avg'].iloc[0] - dem_point['political_avg'].iloc[0])\n",
    "                        distances.append((congress, distance))\n",
    "                \n",
    "                polarization_data[issue] = distances\n",
    "        \n",
    "        # Create streamgraph\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "        \n",
    "        # Prepare data for streamgraph\n",
    "        issues = list(polarization_data.keys())\n",
    "        congresses = sorted(set(c for d in polarization_data.values() for c, _ in d))\n",
    "        data = np.zeros((len(issues), len(congresses)))\n",
    "        \n",
    "        for i, issue in enumerate(issues):\n",
    "            for j, congress in enumerate(congresses):\n",
    "                matching = [d for c, d in polarization_data[issue] if c == congress]\n",
    "                if matching:\n",
    "                    data[i, j] = matching[0]\n",
    "        \n",
    "        # Create streamgraph\n",
    "        ax.stackplot(congresses, data, labels=issues, baseline='sym')\n",
    "        \n",
    "        plt.title('Political Spectrum Polarization by Issue Over Time')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Political Spectrum Gap (R-D)')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{save_dir}/political_polarization_streamgraph.png\")\n",
    "        plt.close()\n",
    "\n",
    "    def plot_issue_network(self, save_dir: str = 'enhanced_plots'):\n",
    "        \"\"\"Create network visualization showing issue relationships and shifts\"\"\"\n",
    "        try:\n",
    "            # Create graph\n",
    "            G = nx.Graph()\n",
    "            \n",
    "            # Add nodes for each issue\n",
    "            for issue in self.metadata['valid_issues']:\n",
    "                if issue in self.trend_data['by_issue']:\n",
    "                    df = pd.DataFrame(self.trend_data['by_issue'][issue])\n",
    "                    \n",
    "                    # Calculate average position and change over time\n",
    "                    start_pos = np.array([df['political_avg'].iloc[0], df['emotional_avg'].iloc[0]])\n",
    "                    end_pos = np.array([df['political_avg'].iloc[-1], df['emotional_avg'].iloc[-1]])\n",
    "                    shift_magnitude = np.linalg.norm(end_pos - start_pos)\n",
    "                    \n",
    "                    G.add_node(issue, shift=shift_magnitude, pos=end_pos)\n",
    "            \n",
    "            # Add edges between issues that shifted similarly\n",
    "            for issue1 in G.nodes():\n",
    "                for issue2 in G.nodes():\n",
    "                    if issue1 < issue2:\n",
    "                        shift1 = G.nodes[issue1]['shift']\n",
    "                        shift2 = G.nodes[issue2]['shift']\n",
    "                        if abs(shift1 - shift2) < 0.5:  # Threshold for similarity\n",
    "                            G.add_edge(issue1, issue2, weight=1/(abs(shift1 - shift2) + 0.1))\n",
    "            \n",
    "            # Draw network\n",
    "            plt.figure(figsize=(15, 15))\n",
    "            pos = nx.spring_layout(G)\n",
    "            \n",
    "            # Draw nodes\n",
    "            node_sizes = [G.nodes[node]['shift'] * 1000 for node in G.nodes()]\n",
    "            nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_sizes, \n",
    "                                 cmap='viridis', alpha=0.7)\n",
    "            \n",
    "            # Draw edges\n",
    "            edge_weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "            nx.draw_networkx_edges(G, pos, width=edge_weights, alpha=0.4)\n",
    "            \n",
    "            # Add labels\n",
    "            nx.draw_networkx_labels(G, pos)\n",
    "            \n",
    "            plt.title('Issue Relationship Network\\n(Node size = magnitude of shift, Edge weight = similarity of shift)')\n",
    "            plt.axis('off')\n",
    "            plt.savefig(f\"{save_dir}/issue_network.png\")\n",
    "            plt.close()\n",
    "        except ImportError:\n",
    "            print(\"NetworkX required for network visualization\")\n",
    "    \n",
    "    # Original visualization methods\n",
    "    def recreate_party_trends(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate party-level trend plots\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Emotional Intensity by Party\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for party in ['D', 'R']:\n",
    "            df = pd.DataFrame(self.trend_data['by_party'][party])\n",
    "            plt.plot(df['congress'], df['emotional_avg'], \n",
    "                    label=f\"{'Democratic' if party == 'D' else 'Republican'}\")\n",
    "        \n",
    "        plt.title('Emotional Intensity by Party Over Time')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Average Emotional Intensity')\n",
    "        plt.ylim(1, 5)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{save_dir}/emotional_intensity_by_party.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for party in ['D', 'R']:\n",
    "            df = pd.DataFrame(self.trend_data['by_party'][party])\n",
    "            plt.plot(df['congress'], df['political_avg'],\n",
    "                    label=f\"{'Democratic' if party == 'D' else 'Republican'}\")\n",
    "\n",
    "        plt.title('Political Spectrum Position by Party Over Time', fontsize=16)\n",
    "        plt.xlabel('Congress', fontsize=16)\n",
    "        plt.ylabel('Average Political Spectrum Position', fontsize=16)\n",
    "        plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "        plt.ylim(1, 5)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.savefig(f\"{save_dir}/political_spectrum_by_party.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def recreate_issue_trends(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate issue-level trend plots\"\"\"\n",
    "        base_dir = os.path.join(save_dir, 'issues')\n",
    "        os.makedirs(base_dir, exist_ok=True)\n",
    "        \n",
    "        for issue in self.metadata['valid_issues']:\n",
    "            issue_dir = os.path.join(base_dir, issue.lower().replace(' ', '_'))\n",
    "            os.makedirs(issue_dir, exist_ok=True)\n",
    "            \n",
    "            # Emotional Intensity\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            for party in ['D', 'R']:\n",
    "                if issue in self.trend_data['by_party_issue'] and \\\n",
    "                party in self.trend_data['by_party_issue'][issue]:\n",
    "                    df = pd.DataFrame(self.trend_data['by_party_issue'][issue][party])\n",
    "                    plt.plot(df['congress'], df['emotional_avg'],\n",
    "                            label=f\"{'Democratic' if party == 'D' else 'Republican'}\")\n",
    "            \n",
    "            plt.title(f'Emotional Intensity Over Time: {issue}')\n",
    "            plt.xlabel('Congress')\n",
    "            plt.ylabel('Average Emotional Intensity')\n",
    "            plt.ylim(1, 5)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(f\"{issue_dir}/emotional_intensity.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            # Political Spectrum\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            for party in ['D', 'R']:\n",
    "                if issue in self.trend_data['by_party_issue'] and \\\n",
    "                party in self.trend_data['by_party_issue'][issue]:\n",
    "                    df = pd.DataFrame(self.trend_data['by_party_issue'][issue][party])\n",
    "                    plt.plot(df['congress'], df['political_avg'],\n",
    "                            label=f\"{'Democratic' if party == 'D' else 'Republican'}\")\n",
    "            \n",
    "            plt.title(f'Political Spectrum Position Over Time: {issue}')\n",
    "            plt.xlabel('Congress')\n",
    "            plt.ylabel('Average Political Spectrum Position')\n",
    "            plt.ylim(1, 5)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(f\"{issue_dir}/political_spectrum.png\")\n",
    "            plt.close()\n",
    "    \n",
    "    def recreate_polarization_trends(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate polarization trend plots\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        df = pd.DataFrame(self.polarization_data['overall'])\n",
    "        plt.plot(df['congress'], df['emotional_gap'], label='Emotional Gap')\n",
    "        plt.plot(df['congress'], df['political_gap'], label='Political Gap')\n",
    "        plt.title('Party Polarization Over Time')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Party Gap')\n",
    "        plt.ylim(-4, 4)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{save_dir}/overall_polarization.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def recreate_issue_heatmaps(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate issue heatmaps\"\"\"\n",
    "        heatmap_dir = os.path.join(save_dir, 'issue_heatmaps')\n",
    "        os.makedirs(heatmap_dir, exist_ok=True)\n",
    "        \n",
    "        # Create shortened labels dictionary\n",
    "        SHORT_LABELS = {\n",
    "            'Immigration and Border Policy': 'Immigration',\n",
    "            'Health and Social Services': 'Healthcare',\n",
    "            'Environment and Energy': 'Environment',\n",
    "            'Justice and Civil Rights': 'Justice',\n",
    "            'Defense and Security': 'Defense',\n",
    "            'Economy and Jobs': 'Economy',\n",
    "            'Budget and Fiscal Responsibility': 'Budget',\n",
    "            'Education and Innovation': 'Education',\n",
    "            'Infrastructure and Transportation': 'Infrastructure'\n",
    "        }\n",
    "        \n",
    "        # Get all congresses and issues\n",
    "        congresses = sorted(self.raw_data.keys(), key=int)\n",
    "        issues = list(self.metadata['valid_issues'])\n",
    "        \n",
    "        # Initialize matrices\n",
    "        prevalence_matrix = np.zeros((len(issues), len(congresses)))\n",
    "        emotional_matrix = np.zeros((len(issues), len(congresses)))\n",
    "        political_matrix = np.zeros((len(issues), len(congresses)))\n",
    "        \n",
    "        # Fill matrices using raw data\n",
    "        for i, issue in enumerate(issues):\n",
    "            for j, congress in enumerate(congresses):\n",
    "                df = pd.DataFrame(self.raw_data[congress])\n",
    "                # Find the LABEL that maps to this issue\n",
    "                issue_label = [k for k, v in self.metadata['issue_map'].items() if v == issue][0]\n",
    "                issue_mask = df['issues'].apply(lambda x: issue_label in x)\n",
    "                issue_df = df[issue_mask]\n",
    "                \n",
    "                if not issue_df.empty:\n",
    "                    prevalence_matrix[i, j] = len(issue_df) / len(df) * 100\n",
    "                    emotional_matrix[i, j] = issue_df['emotional_intensity'].mean()\n",
    "                    political_matrix[i, j] = issue_df['political_spectrum'].mean()\n",
    "        \n",
    "        # Create shortened issue labels\n",
    "        short_issues = [SHORT_LABELS[issue] for issue in issues]\n",
    "        \n",
    "        # Create congress labels for every 5th congress\n",
    "        congress_numbers = [int(x) for x in congresses]  # Convert to integers\n",
    "        congress_labels = [str(x) if int(x) % 5 == 0 else '' for x in congresses]\n",
    "        \n",
    "        # Plot emotional heatmap with modified labels\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        sns.heatmap(emotional_matrix,\n",
    "                    xticklabels=congress_labels,\n",
    "                    yticklabels=short_issues,\n",
    "                    cmap='Purples')\n",
    "        \n",
    "        plt.title('Average Emotional Intensity by Issue Over Time', fontsize=20)\n",
    "        plt.xlabel('Congress', fontsize=20)\n",
    "        plt.ylabel('Issue', fontsize=20)\n",
    "        plt.xticks(fontsize=20)\n",
    "        plt.yticks(fontsize=20, rotation=0)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{heatmap_dir}/issue_emotional.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot heatmaps\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        sns.heatmap(prevalence_matrix,\n",
    "                    xticklabels=congresses,\n",
    "                    yticklabels=issues,\n",
    "                    cmap='YlOrRd')\n",
    "        plt.title('Issue Prevalence Over Time (%)')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Issue')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{heatmap_dir}/issue_prevalence.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        sns.heatmap(political_matrix,\n",
    "                    xticklabels=congresses,\n",
    "                    yticklabels=issues,\n",
    "                    cmap='RdBu_r',\n",
    "                    vmin=1, vmax=5)\n",
    "        plt.title('Average Political Position by Issue Over Time')\n",
    "        plt.xlabel('Congress')\n",
    "        plt.ylabel('Issue')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{heatmap_dir}/issue_political.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def recreate_all_plots(self, save_dir: str = 'recreated_plots'):\n",
    "        \"\"\"Recreate all plots including the new enhanced visualizations\"\"\"\n",
    "        print(\"Recreating all plots...\")\n",
    "        \n",
    "        # Create main directory\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Original plots\n",
    "        print(\"1. Recreating party trends...\")\n",
    "        self.recreate_party_trends(save_dir)\n",
    "        \n",
    "        print(\"2. Recreating issue trends...\")\n",
    "        self.recreate_issue_trends(save_dir)\n",
    "        \n",
    "        print(\"3. Recreating polarization trends...\")\n",
    "        self.recreate_polarization_trends(save_dir)\n",
    "        \n",
    "        print(\"4. Recreating issue heatmaps...\")\n",
    "        self.recreate_issue_heatmaps(save_dir)\n",
    "        \n",
    "        # Enhanced plots\n",
    "        print(\"5. Creating issue evolution matrix plots...\")\n",
    "        self.plot_issue_evolution_matrix(save_dir)\n",
    "        \n",
    "        print(\"6. Creating party polarization streamgraph...\")\n",
    "        self.plot_party_polarization_trends(save_dir)\n",
    "        \n",
    "        print(\"7. Creating issue network visualization...\")\n",
    "        self.plot_issue_network(save_dir)\n",
    "        \n",
    "        print(\"\\nAll plots have been recreated successfully!\")\n",
    "        print(f\"Output directory: {save_dir}\")\n",
    "\n",
    "    def calculate_frameshifting(self, start_congress=79, end_congress=114):\n",
    "        \"\"\"Calculate frameshifting statistics for each issue and party.\"\"\"\n",
    "        \n",
    "        # Define the early and late period ranges\n",
    "        # First 5 congresses in the range [79..83], last 5 in [110..114]\n",
    "        early_period = range(start_congress, start_congress + 5)\n",
    "        late_period = range(end_congress - 4, end_congress + 1)\n",
    "\n",
    "        results = {\n",
    "            'by_issue_party': {},\n",
    "            'aggregate': {}\n",
    "        }\n",
    "        \n",
    "        # Gather lists for aggregate calculations across all issues\n",
    "        all_political_shifts = {'D': [], 'R': []}\n",
    "        all_emotional_shifts = {'D': [], 'R': []}\n",
    "        \n",
    "        issues = self.metadata['valid_issues']\n",
    "        parties = ['D', 'R']\n",
    "        \n",
    "        for issue in issues:\n",
    "            results['by_issue_party'][issue] = {}\n",
    "            \n",
    "            # Make sure issue data is present\n",
    "            if issue not in self.trend_data['by_party_issue']:\n",
    "                continue\n",
    "            \n",
    "            for party in parties:\n",
    "                if party not in self.trend_data['by_party_issue'][issue]:\n",
    "                    continue\n",
    "                    \n",
    "                df = pd.DataFrame(self.trend_data['by_party_issue'][issue][party])\n",
    "                \n",
    "                # Filter to desired congress range and sort\n",
    "                df = df[(df['congress'] >= start_congress) & (df['congress'] <= end_congress)].copy()\n",
    "                df.sort_values(by='congress', inplace=True)\n",
    "                \n",
    "                if df.empty:\n",
    "                    continue\n",
    "                \n",
    "                # Compute early averages\n",
    "                early_df = df[df['congress'].isin(early_period)]\n",
    "                late_df = df[df['congress'].isin(late_period)]\n",
    "                \n",
    "                if early_df.empty or late_df.empty:\n",
    "                    # If we don't have full coverage, we can skip\n",
    "                    continue\n",
    "                \n",
    "                early_political_avg = early_df['political_avg'].mean()\n",
    "                early_emotional_avg = early_df['emotional_avg'].mean()\n",
    "                late_political_avg = late_df['political_avg'].mean()\n",
    "                late_emotional_avg = late_df['emotional_avg'].mean()\n",
    "                \n",
    "                # Compute shifts\n",
    "                political_shift = late_political_avg - early_political_avg\n",
    "                emotional_shift = late_emotional_avg - early_emotional_avg\n",
    "                \n",
    "                # Store results\n",
    "                issue_party_key = f\"{issue}_{party}\"\n",
    "                results['by_issue_party'][issue][party] = {\n",
    "                    'early_political_avg': early_political_avg,\n",
    "                    'late_political_avg': late_political_avg,\n",
    "                    'political_shift': political_shift,\n",
    "                    'early_emotional_avg': early_emotional_avg,\n",
    "                    'late_emotional_avg': late_emotional_avg,\n",
    "                    'emotional_shift': emotional_shift,\n",
    "                }\n",
    "                \n",
    "                # Add to aggregate\n",
    "                all_political_shifts[party].append(political_shift)\n",
    "                all_emotional_shifts[party].append(emotional_shift)\n",
    "                \n",
    "                # Find largest successive congress delta for political and emotional averages\n",
    "                # look at consecutive entries in df\n",
    "                df_sorted = df.sort_values(by='congress')\n",
    "                df_sorted['political_delta'] = df_sorted['political_avg'].diff()\n",
    "                df_sorted['emotional_delta'] = df_sorted['emotional_avg'].diff()\n",
    "                \n",
    "                # Identify the largest absolute changes\n",
    "                max_political_delta = df_sorted['political_delta'].abs().max()\n",
    "                max_emotional_delta = df_sorted['emotional_delta'].abs().max()\n",
    "                \n",
    "                # Which congresses caused these max deltas?\n",
    "                max_pol_delta_row = df_sorted.iloc[df_sorted['political_delta'].abs().idxmax()]\n",
    "                max_emot_delta_row = df_sorted.iloc[df_sorted['emotional_delta'].abs().idxmax()]\n",
    "                \n",
    "                # Because delta is between successive congresses, we need to find the pair\n",
    "                # The congress associated with delta is the \"current\" row; \n",
    "                # The previous congress would be previous row\n",
    "                pol_indices = df_sorted.index[df_sorted['political_delta'].abs() == max_political_delta]\n",
    "                emot_indices = df_sorted.index[df_sorted['emotional_delta'].abs() == max_emotional_delta]\n",
    "                \n",
    "                # For simplicity, take the first occurrence if multiple maxes\n",
    "                pol_idx = pol_indices[0] if len(pol_indices) > 0 else None\n",
    "                emot_idx = emot_indices[0] if len(emot_indices) > 0 else None\n",
    "                \n",
    "                # Retrieve congress pair for political\n",
    "                if pol_idx is not None:\n",
    "                    pol_congress_current = df_sorted.loc[pol_idx, 'congress']\n",
    "                    # The previous congress's row should be one before pol_idx\n",
    "                    # But we need to ensure pol_idx - 1 is in the dataset\n",
    "                    pol_prev_congress = df_sorted.iloc[df_sorted.index.get_loc(pol_idx)-1]['congress'] if df_sorted.index.get_loc(pol_idx)-1 >= 0 else None\n",
    "                else:\n",
    "                    pol_congress_current, pol_prev_congress = None, None\n",
    "                \n",
    "                # Retrieve congress pair for emotional\n",
    "                if emot_idx is not None:\n",
    "                    emot_congress_current = df_sorted.loc[emot_idx, 'congress']\n",
    "                    emot_prev_congress = df_sorted.iloc[df_sorted.index.get_loc(emot_idx)-1]['congress'] if df_sorted.index.get_loc(emot_idx)-1 >= 0 else None\n",
    "                else:\n",
    "                    emot_congress_current, emot_prev_congress = None, None\n",
    "                \n",
    "                # Store these deltas\n",
    "                results['by_issue_party'][issue][party].update({\n",
    "                    'max_political_delta': max_political_delta,\n",
    "                    'max_political_delta_congresses': (pol_prev_congress, pol_congress_current),\n",
    "                    'max_emotional_delta': max_emotional_delta,\n",
    "                    'max_emotional_delta_congresses': (emot_prev_congress, emot_congress_current)\n",
    "                })\n",
    "        \n",
    "        # Compute aggregate results across all issues\n",
    "        for party in parties:\n",
    "            if all_political_shifts[party]:\n",
    "                avg_political_shift = np.mean(all_political_shifts[party])\n",
    "            else:\n",
    "                avg_political_shift = None\n",
    "            \n",
    "            if all_emotional_shifts[party]:\n",
    "                avg_emotional_shift = np.mean(all_emotional_shifts[party])\n",
    "            else:\n",
    "                avg_emotional_shift = None\n",
    "            \n",
    "            results['aggregate'][party] = {\n",
    "                'avg_political_shift': avg_political_shift,\n",
    "                'avg_emotional_shift': avg_emotional_shift\n",
    "            }\n",
    "\n",
    "        print(\"Frameshifting Results:\")\n",
    "        print(\"Aggregates:\")\n",
    "        for party in parties:\n",
    "            print(f\"  {party}: Avg Political Shift = {results['aggregate'][party]['avg_political_shift']}, Avg Emotional Shift = {results['aggregate'][party]['avg_emotional_shift']}\")\n",
    "        \n",
    "        print(\"\\nBy Issue and Party:\")\n",
    "        for issue in results['by_issue_party']:\n",
    "            for party in parties:\n",
    "                if party in results['by_issue_party'][issue]:\n",
    "                    vals = results['by_issue_party'][issue][party]\n",
    "                    print(f\"Issue: {issue}, Party: {party}\")\n",
    "                    print(f\"  Early Political Avg: {vals['early_political_avg']:.2f}, Late Political Avg: {vals['late_political_avg']:.2f}, Shift: {vals['political_shift']:.2f}\")\n",
    "                    print(f\"  Early Emotional Avg: {vals['early_emotional_avg']:.2f}, Late Emotional Avg: {vals['late_emotional_avg']:.2f}, Shift: {vals['emotional_shift']:.2f}\")\n",
    "                    print(f\"  Max Political Delta: {vals['max_political_delta']:.2f} (between Congresses {vals['max_political_delta_congresses']})\")\n",
    "                    print(f\"  Max Emotional Delta: {vals['max_emotional_delta']:.2f} (between Congresses {vals['max_emotional_delta_congresses']})\\n\")\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreating all plots...\n",
      "1. Recreating party trends...\n",
      "2. Recreating issue trends...\n",
      "3. Recreating polarization trends...\n",
      "4. Recreating issue heatmaps...\n",
      "5. Creating issue evolution matrix plots...\n",
      "6. Creating party polarization streamgraph...\n",
      "7. Creating issue network visualization...\n",
      "\n",
      "All plots have been recreated successfully!\n",
      "Output directory: enhanced_plots\n",
      "Frameshifting Results:\n",
      "Aggregates:\n",
      "  D: Avg Political Shift = -0.5678000095849899, Avg Emotional Shift = 0.6979176835039582\n",
      "  R: Avg Political Shift = 0.043799793274794316, Avg Emotional Shift = 0.6691645371998427\n",
      "\n",
      "By Issue and Party:\n",
      "Issue: Immigration and Border Policy, Party: D\n",
      "  Early Political Avg: 3.00, Late Political Avg: 2.37, Shift: -0.63\n",
      "  Early Emotional Avg: 2.56, Late Emotional Avg: 3.16, Shift: 0.60\n",
      "  Max Political Delta: 1.50 (between Congresses (np.float64(93.0), np.int64(94)))\n",
      "  Max Emotional Delta: 1.20 (between Congresses (np.float64(92.0), np.int64(93)))\n",
      "\n",
      "Issue: Immigration and Border Policy, Party: R\n",
      "  Early Political Avg: 2.93, Late Political Avg: 2.69, Shift: -0.25\n",
      "  Early Emotional Avg: 2.59, Late Emotional Avg: 3.27, Shift: 0.68\n",
      "  Max Political Delta: 2.00 (between Congresses (np.float64(92.0), np.int64(93)))\n",
      "  Max Emotional Delta: 1.10 (between Congresses (np.float64(98.0), np.int64(99)))\n",
      "\n",
      "Issue: Health and Social Services, Party: D\n",
      "  Early Political Avg: 2.67, Late Political Avg: 2.00, Shift: -0.66\n",
      "  Early Emotional Avg: 2.77, Late Emotional Avg: 3.58, Shift: 0.81\n",
      "  Max Political Delta: 0.32 (between Congresses (np.float64(111.0), np.int64(112)))\n",
      "  Max Emotional Delta: 0.42 (between Congresses (np.float64(103.0), np.int64(104)))\n",
      "\n",
      "Issue: Health and Social Services, Party: R\n",
      "  Early Political Avg: 2.74, Late Political Avg: 3.02, Shift: 0.28\n",
      "  Early Emotional Avg: 2.71, Late Emotional Avg: 3.41, Shift: 0.70\n",
      "  Max Political Delta: 0.65 (between Congresses (np.float64(113.0), np.int64(114)))\n",
      "  Max Emotional Delta: 0.60 (between Congresses (np.float64(98.0), np.int64(99)))\n",
      "\n",
      "Issue: Environment and Energy, Party: D\n",
      "  Early Political Avg: 2.91, Late Political Avg: 2.40, Shift: -0.51\n",
      "  Early Emotional Avg: 2.41, Late Emotional Avg: 3.02, Shift: 0.62\n",
      "  Max Political Delta: 0.72 (between Congresses (np.float64(89.0), np.int64(90)))\n",
      "  Max Emotional Delta: 0.67 (between Congresses (np.float64(89.0), np.int64(90)))\n",
      "\n",
      "Issue: Environment and Energy, Party: R\n",
      "  Early Political Avg: 2.85, Late Political Avg: 3.06, Shift: 0.21\n",
      "  Early Emotional Avg: 2.36, Late Emotional Avg: 3.01, Shift: 0.65\n",
      "  Max Political Delta: 0.56 (between Congresses (np.float64(88.0), np.int64(89)))\n",
      "  Max Emotional Delta: 0.66 (between Congresses (np.float64(107.0), np.int64(108)))\n",
      "\n",
      "Issue: Justice and Civil Rights, Party: D\n",
      "  Early Political Avg: 3.01, Late Political Avg: 2.11, Shift: -0.90\n",
      "  Early Emotional Avg: 2.54, Late Emotional Avg: 3.46, Shift: 0.92\n",
      "  Max Political Delta: 0.28 (between Congresses (np.float64(112.0), np.int64(113)))\n",
      "  Max Emotional Delta: 0.51 (between Congresses (np.float64(96.0), np.int64(97)))\n",
      "\n",
      "Issue: Justice and Civil Rights, Party: R\n",
      "  Early Political Avg: 2.99, Late Political Avg: 2.84, Shift: -0.15\n",
      "  Early Emotional Avg: 2.48, Late Emotional Avg: 3.32, Shift: 0.84\n",
      "  Max Political Delta: 0.39 (between Congresses (np.float64(110.0), np.int64(111)))\n",
      "  Max Emotional Delta: 0.36 (between Congresses (np.float64(109.0), np.int64(110)))\n",
      "\n",
      "Issue: Defense and Security, Party: D\n",
      "  Early Political Avg: 2.95, Late Political Avg: 2.55, Shift: -0.40\n",
      "  Early Emotional Avg: 2.74, Late Emotional Avg: 3.28, Shift: 0.55\n",
      "  Max Political Delta: 0.36 (between Congresses (np.float64(110.0), np.int64(111)))\n",
      "  Max Emotional Delta: 0.54 (between Congresses (np.float64(96.0), np.int64(97)))\n",
      "\n",
      "Issue: Defense and Security, Party: R\n",
      "  Early Political Avg: 3.07, Late Political Avg: 2.98, Shift: -0.09\n",
      "  Early Emotional Avg: 2.62, Late Emotional Avg: 3.26, Shift: 0.64\n",
      "  Max Political Delta: 0.32 (between Congresses (np.float64(92.0), np.int64(93)))\n",
      "  Max Emotional Delta: 0.48 (between Congresses (np.float64(106.0), np.int64(107)))\n",
      "\n",
      "Issue: Economy and Jobs, Party: D\n",
      "  Early Political Avg: 2.92, Late Political Avg: 2.17, Shift: -0.75\n",
      "  Early Emotional Avg: 2.60, Late Emotional Avg: 3.44, Shift: 0.84\n",
      "  Max Political Delta: 0.30 (between Congresses (np.float64(107.0), np.int64(108)))\n",
      "  Max Emotional Delta: 0.35 (between Congresses (np.float64(96.0), np.int64(97)))\n",
      "\n",
      "Issue: Economy and Jobs, Party: R\n",
      "  Early Political Avg: 2.96, Late Political Avg: 3.20, Shift: 0.24\n",
      "  Early Emotional Avg: 2.55, Late Emotional Avg: 3.21, Shift: 0.66\n",
      "  Max Political Delta: 0.52 (between Congresses (np.float64(113.0), np.int64(114)))\n",
      "  Max Emotional Delta: 0.25 (between Congresses (np.float64(109.0), np.int64(110)))\n",
      "\n",
      "Issue: Budget and Fiscal Responsibility, Party: D\n",
      "  Early Political Avg: 2.99, Late Political Avg: 2.52, Shift: -0.47\n",
      "  Early Emotional Avg: 2.21, Late Emotional Avg: 3.01, Shift: 0.79\n",
      "  Max Political Delta: 0.28 (between Congresses (np.float64(109.0), np.int64(110)))\n",
      "  Max Emotional Delta: 0.69 (between Congresses (np.float64(109.0), np.int64(110)))\n",
      "\n",
      "Issue: Budget and Fiscal Responsibility, Party: R\n",
      "  Early Political Avg: 3.04, Late Political Avg: 3.40, Shift: 0.36\n",
      "  Early Emotional Avg: 2.28, Late Emotional Avg: 2.93, Shift: 0.65\n",
      "  Max Political Delta: 0.24 (between Congresses (np.float64(109.0), np.int64(110)))\n",
      "  Max Emotional Delta: 0.43 (between Congresses (np.float64(110.0), np.int64(111)))\n",
      "\n",
      "Issue: Education and Innovation, Party: D\n",
      "  Early Political Avg: 2.70, Late Political Avg: 2.30, Shift: -0.40\n",
      "  Early Emotional Avg: 2.61, Late Emotional Avg: 3.22, Shift: 0.60\n",
      "  Max Political Delta: 0.32 (between Congresses (np.float64(85.0), np.int64(86)))\n",
      "  Max Emotional Delta: 0.67 (between Congresses (np.float64(103.0), np.int64(104)))\n",
      "\n",
      "Issue: Education and Innovation, Party: R\n",
      "  Early Political Avg: 2.95, Late Political Avg: 2.74, Shift: -0.21\n",
      "  Early Emotional Avg: 2.26, Late Emotional Avg: 2.90, Shift: 0.64\n",
      "  Max Political Delta: 0.55 (between Congresses (np.float64(97.0), np.int64(98)))\n",
      "  Max Emotional Delta: 0.81 (between Congresses (np.float64(83.0), np.int64(84)))\n",
      "\n",
      "Issue: Infrastructure and Transportation, Party: D\n",
      "  Early Political Avg: 2.92, Late Political Avg: 2.54, Shift: -0.38\n",
      "  Early Emotional Avg: 2.29, Late Emotional Avg: 2.84, Shift: 0.55\n",
      "  Max Political Delta: 0.51 (between Congresses (np.float64(108.0), np.int64(109)))\n",
      "  Max Emotional Delta: 1.08 (between Congresses (np.float64(107.0), np.int64(108)))\n",
      "\n",
      "Issue: Infrastructure and Transportation, Party: R\n",
      "  Early Political Avg: 2.97, Late Political Avg: 2.97, Shift: 0.00\n",
      "  Early Emotional Avg: 2.20, Late Emotional Avg: 2.77, Shift: 0.56\n",
      "  Max Political Delta: 0.44 (between Congresses (np.float64(107.0), np.int64(108)))\n",
      "  Max Emotional Delta: 0.84 (between Congresses (np.float64(96.0), np.int64(97)))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recreator = PlotRecreator(data_dir='analysis_results')\n",
    "recreator.recreate_all_plots(save_dir='enhanced_plots')\n",
    "frameshift_results = recreator.calculate_frameshifting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
